# VAE
> 论文：https://arxiv.org/pdf/1312.6114
> 苏剑林：https://kexue.fm/archives/5253
> 翁丽莲：https://lilianweng.github.io/posts/2018-08-12-vae/
> 余正阳：https://www.bilibili.com/video/BV1Mgh4zJEZV
## 入门问题
第一次看论文的时候其实是懵圈的：
1. $p_\theta(\bm z),p_\theta(\bm x|\bm z),p_\theta(\bm z|\bm x)$怎么理解，他们是同一个分布还是不同的分布？如果是不同分布为什么都用同一个下标theta？
2. 前边这一坨还没看懂，后边怎么突然就又搞了个$q_\phi(\bm z|\bm x)$？p和q的区别是什么，为啥(z|x)还能有两个不同的分布？
   
关于第一个问题，许多博客都没有细说，论文里反而有一部分说明：
> We assume that the data are generated by some random process, involving an unobserved continuous random variable z. The process consists of two steps: (1) a value $\bm z^{(i)}$is generated from some prior distribution$p_{\theta^*}(\bm z)$;(2)a value $\bm x^{(i)}$is generated from some conditional distribution $p_{\theta^*}(\bm x|\bm z)$.We assume that the prior $p_{\theta^*}(\bm z)$ and likelihood $p_{\theta^*}(\bm x|\bm z)$ come from parametric families of distributions $p_{\theta}(\bm z)$ and $p_{\theta}(\bm x|\bm z)$

论文里说：$p_\theta(\bm z),p_\theta(\bm x|\bm z)$分别是两个参数化的分布族（参数为$\theta$），他们分别表示隐状态向量分布和给定一个隐向量条件下真实数据的分布。
> 为什么要搞这么多分布呢？苏剑林博客：我们的终极目标是为了求$p(\mathbf x)$，但是这个没法直接求，因此只能走迂回战术$p(\mathbf x)=\int p(\mathbf x|\mathbf z)p(\mathbf z)d\mathbf z$，我们假定一个隐藏变量z属于某个固定分布（比如标准高斯）那我们就能够通过在这个固定分布中采样一个z，然后根据z来生成x

那为什么他们都是同一个下标$\theta$呢？我们可以这样理解：这里的$\theta,\phi$实际指的是模型（神经网络），所以这里有两个模型，$\theta$指的是将隐变量转换成真实数据的模型（生成模型）$p_{\theta}(\bm x|\bm z)$，理论上这个模型当然也存在$p_{\theta}(\bm z|\bm x)$，但是由于模型它是个生成模型所以无法直接求，得通过贝叶斯间接求，然后就遇到了$p_\theta(\bm x)$无法求解的问题，所以用生成模型直接求后验分布是不可行的(intractable)。然后就有第二个问题。



关于第二个问题，论文中也有解释但是表述地不是很清晰，翁丽莲有解释：
>The optimal parameter $\theta^*$ is the one that maximizes the probability of generating real data samples:
$\theta^{*} = \displaystyle \arg\max_\theta \sum_{i=1}^n \log p_\theta(\mathbf{x}^{(i)})$，其中$p_\theta(\mathbf{x}^{(i)}) = \int p_\theta(\mathbf{x}^{(i)}\vert\mathbf{z}) p_\theta(\mathbf{z}) d\mathbf{z}$
Unfortunately it is not easy to compute $p_\theta(\mathbf{x}^{(i)})$ in this way, as it is very expensive to check all the possible values of $\mathbf z$ and sum them up. To narrow down the value space to facilitate faster search, we would like to introduce a new approximation function to output what is a likely code given an input $\mathbf x$, $q_\phi(\mathbf{z}\vert\mathbf{x})$ parameterized by $\phi$.
![翁立莲的博客图片](https://lilianweng.github.io/posts/2018-08-12-vae/VAE-graphical-model.png)

个人感觉这里解释也不是很详细，所以作一下展开：

简单说，我们无法在同一个模型（神经网络）上同时计算后验$p_{\theta}(\bm z|\bm x)$和似然$p_{\theta}(\bm x|\bm z)$，理由在上边第一个问题的回答里已经说过了。于是另开了一个模型$q_\phi(\bm z|\bm x)$，它的参数为$\phi$，用它来近似$p_{\theta}(\bm z|\bm x)$。

那么现在的问题来了，这里有两个模型，我们要怎么训练呢？

## 证据下界
$\log p_\theta(x)$的证据下界(ELBO)
```math
\mathcal{L}=-D_{KL}(q_{\phi}(\bm z|\bm x^{(i)})||p_{\theta}(\bm z))+\Bbb E_{q_{\phi}(\bm z|\bm x^{(i)})}[\log p_{\theta}(\bm x^{(i)}|\bm z)]
```
这个式子是用KL散度的定义推出来的
```math
D_{KL}(q(\bm z|\bm x)||p(\bm z|\bm x))=\Bbb E_{z\sim q}[\log q(\bm z|\bm x)-\log p(\bm z|\bm x)]\\
=\Bbb E_{z\sim q}\Big[\log q(\bm z|\bm x) - \log \frac {p(\bm x|\bm z)p(\bm z)} {p(\bm x)}\Big]\\
=\Bbb E_{z\sim q}\Big[\log q(\bm z|\bm x) - \log p(\bm x|\bm z) -\log p(\bm z) + \log p(\bm x)\Big ]\\
=\log p(\bm x) +\Bbb E_{z\sim q}\Big[\log q(\bm z|\bm x) - \log p(\bm x|\bm z) -\log p(\bm z) \Big ]\\


```
观察到$\log p(\bm x)$就是我们希望最大化的目标函数，因此改写此式为：
```math
\log p(\bm x)=D_{KL}(q(\bm z|\bm x)||p(\bm z|\bm x))+\Bbb E_{z\sim q}\Big[-\log q(\bm z|\bm x) + \log p(\bm x|\bm z) +\log p(\bm z) \Big ]\\
=D_{KL}(q(\bm z|\bm x)||p(\bm z|\bm x))- D_{KL}(q(\bm z|\bm x)||p(\bm z)) + \Bbb E_{z\sim q}[\log p(\bm x|\bm z)]
```
因为等是右边的第一项是KL散度，一定大于0,因此有
```math
\log p(\bm x)\ge - D_{KL}(q(\bm z|\bm x)||p(\bm z)) + \Bbb E_{z\sim q}[\log p(\bm x|\bm z)]
```
不等号右边即为证据下界
> 证据下界中的“证据”(evidence)是什么意思？来源是贝叶斯定理
> $P(H|D) = \frac {P(D|H)\cdot P(H)} {P(D)}$
> 这个公式中，H表示隐藏状态，我们无法直接观测的，因此我们只能根据经验猜一个分布，这个分布叫先验(prior)；D表示显性状态，我们可以通过实验观察到，因此它的概率称为证据(evidence)；我们相信某个隐藏状态H的假设，求某个显性状态的概率P(D|H)是似然度(likelihood)；以及我们在观察到某个显性状态已经发生的情况下，对隐藏状态的分布为后验(posterior)P(H|D)
> - P(H)：先验，根据经验猜的
> - P(H|D)：后验，某个显性状态发生后的条件概率，一般作为目标
> - P(D|H)：似然度，相信隐藏状态假设，算某个显性状态发生的概率
> - P(D)：证据，即数据的边际概率(minal probability)
> 
> VAE的目标是最大化$\log p_\theta(x)$，而这里的$p_\theta(x)$就是证据，因为x表示的是显性数据。根据上边的推导，它的下界就是证据下界。

## 
