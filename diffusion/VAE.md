# VAE学习笔记
>论文： https://arxiv.org/pdf/1312.6114
## 入门问题
第一次看论文的时候其实是懵的：
1.  $p_\theta(\mathbf z),p_\theta(\mathbf x|\mathbf z),p_\theta(\mathbf z|\mathbf x)$ 怎么理解，他们是同一个分布还是不同的分布？如果是不同分布为什么都用同一个下标 $\theta$？
2. 前边这一坨还没看懂，后边怎么突然就又搞了个 $q_\phi(\mathbf z|\mathbf x)$ ？p和q的区别是什么，为啥(z|x)还能有两个不同的分布？
> 

关于第一个问题，论文里有一部分说明：
> We assume that the data are generated by some random process, involving an unobserved continuous random variable z. The process consists of two steps: (1) a value $\mathbf z^{(i)}$ is generated from some prior distribution $p_{\theta^{best}}(\mathbf z)$ ;(2)a value $\mathbf x^{(i)}$ is generated from some conditional distribution $p_{\theta^{best}}(\mathbf x|\mathbf z)$ .We assume that the prior $p_{\theta^{best}}(\mathbf z)$ and likelihood $p_{\theta^{best}}(\mathbf x|\mathbf z)$ come from parametric families of distributions $p_{\theta}(\mathbf z)$ and $p_{\theta}(\mathbf x|\mathbf z)$

为什么要搞这么多分布呢？引用[3]，我们的终极目标是为了求 $p(\mathbf x)$ ，但是这个没法直接求，因此只能走迂回战术 $p(\mathbf x)=\int p(\mathbf x|\mathbf z)p(\mathbf z)d\mathbf z$ ，我们假定一个隐藏变量z属于某个固定分布（比如标准高斯）那我们就能够通过在这个固定分布中采样一个z，然后根据z来生成x。
$p_\theta(\mathbf z),p_\theta(\mathbf x|\mathbf z),p_\theta(\mathbf z|\mathbf x)$ 分别是三个参数化的分布族，参数为 $\theta$ ，分别表示先验、似然和后验概率分布。那为什么他们都是同一个下标 $\theta$ 呢？我们可以这样理解：这里的 $\theta,\phi$ 实际指的是一个参数集合，分别表示生成模型(generative model)和识别（推断）模型(recognition/inference model)的参数集合。你当然可以把它拆，开例如把生成模型的先验、似然和后验写成 $p_{\theta_1}(\mathbf z),p_{\theta_2}(\mathbf x|\mathbf z),p_{\theta_3}(\mathbf z|\mathbf x)$ ，但这样在书写和理解上会增加额外负担，不如在模型维度上把他们统一起来 $\theta=\{\theta_1,\theta_2\,\theta_3\}$ 。

> 先验、后验、似然、证据是来源于贝叶斯定理的概念：
> $$P(H|D) = \frac {P(D|H)\cdot P(H)} {P(D)}$$
> 这个公式中，H表示隐藏状态，我们无法直接观测，只能根据经验猜一个分布，这个分布叫先验(prior)；D表示显性状态，我们可以通过实验观察到，因此它的概率称为证据(evidence)；我们相信某个隐藏状态H的假设，求某个显性状态的概率P(D|H)是似然度(likelihood)；以及我们在观察到某个显性状态已经发生的情况下，对隐藏状态的分布为后验(posterior)P(H|D)
> - P(H)：先验，根据经验猜的
> - P(H|D)：后验，某个显性状态发生后的条件概率，一般作为目标
> - P(D|H)：似然度，相信隐藏状态假设，算某个显性状态发生的概率
> - P(D)：证据，即数据的边际概率(marginal probability)
>
> 给定一个观测数据，求隐变量的后验分布 $p(\mathbf z|\mathbf x)$ 被称为**推断**任务(inference task)，常用方法有VB(Variational Bayes)和MCMC(Markov Chain Monte Carlo)。VB也叫VBI(Variational Bayes Inference)。VAE利用了VB的理论基础，这就是它名字中"V"的由来。

关于第二个问题，论文中也有解释但是表述地不是很清晰，翁丽莲的解释：
>The optimal parameter $\theta^{best}$ is the one that maximizes the probability of generating real data samples:
$\theta^{best} = \displaystyle \arg\max_\theta \sum_{i=1}^n \log p_\theta(\mathbf{x}^{(i)})$，其中 $p_\theta(\mathbf{x}^{(i)}) = \int p_\theta(\mathbf{x}^{(i)}\vert\mathbf{z}) p_\theta(\mathbf{z}) d\mathbf{z}$
Unfortunately it is not easy to compute $p_\theta(\mathbf{x}^{(i)})$ in this way, as it is very expensive to check all the possible values of $\mathbf z$ and sum them up. To narrow down the value space to facilitate faster search, we would like to introduce a new approximation function to output what is a likely code given an input $\mathbf x$, $q_\phi(\mathbf{z}\vert\mathbf{x})$ parameterized by $\phi$.
![翁立莲的博客图片](/resource/vae_process_by_wenglilian.png)

1. 为什么原来的 $p_\theta(\mathbf{z}|\mathbf{x})$ 不可解？根据贝叶斯公式： $p_\theta(\mathbf{z}|\mathbf{x}) = \frac{p_\theta(\mathbf{x}|\mathbf{z})p(\mathbf{z})}{\int p_\theta(\mathbf{x}|\mathbf{z})p(\mathbf{z})d\mathbf{z}}$ 它的难点在于分母的积分。要把所有可能的 $\mathbf{z}$ 都积一遍，这在高维空间是不可能的。所以我们不知道这个分布到底长什么样，更算不出它的概率密度值。

2. 为什么新引入的 $q_\phi(\mathbf{z}|\mathbf{x})$ 是可解的？因为 $q_\phi$ 是我们人为设计的。我们在设计模型时，会强制假设 $q_\phi(\mathbf{z}|\mathbf{x})$ 服从一个已知且简单的分布，最常见的就是高斯分布： $q_\phi(\mathbf{z}|\mathbf{x}) = \mathcal{N}(\mathbf{z}; \mu_\phi(\mathbf{x}), \sigma^2_\phi(\mathbf{x})\mathcal{I})$ 这里 $\mu_\phi(\mathbf{x})$ 和 $\sigma_\phi(\mathbf{x})$ 是由神经网络（Encoder）算出来的具体数值。因为我们假设它是高斯分布：
    - 采样容易 ：我们可以轻松地从高斯分布里采样出 $\mathbf{z}$（重参数化技巧）。
    - 计算概率密度容易 ：我们可以直接套用高斯分布公式算出 $\log q_\phi(\mathbf{z}|\mathbf{x})$ 的值。
3. 核心逻辑：把“计算问题”转化为“优化问题”。引入变分推断后，我们的思路变了：
    - 以前（死胡同） ：试图硬算那个积分，求出真实的 $p_\theta(\mathbf{z}|\mathbf{x})$。 $\rightarrow$ 算不出来。
    - 现在（变分推断） ：既然算不出来，那我就在一个我熟悉的分布家族（比如高斯分布家族）里，找一个**长得最像**真实后验的分布。这就把问题转化为了一个 优化问题 ：调整神经网络 $\phi$ 的参数（也就是调整高斯分布的均值和方差），让 $q_\phi$ 和未知的 $p_\theta$ 之间的距离（KL 散度）最小。

4. 妙在何处？（ELBO）
你可能会问： “既然不知道真实的 $p_\theta$，怎么还能最小化它俩的距离呢？”
这就是变分推断最精妙的地方。数学上可以推导出： $\log p_\theta(\mathbf{x}) - D_{KL}(q_\phi || p_\theta) = \text{ELBO}$ 
最大化 ELBO（证据下界） 等价于最小化 KL 散度。
而 ELBO 里的每一项： $\text{ELBO} = \mathbb{E} {q}[\log p \theta(\mathbf{x}|\mathbf{z})] - D_{KL}(q_\phi(\mathbf{z}|\mathbf{x}) || p(\mathbf{z}))$

- $p_\theta(\mathbf{x}|\mathbf{z})$：是 Decoder（我们设计的，可算）。
- $q_\phi(\mathbf{z}|\mathbf{x})$：是 Encoder 输出的高斯（我们设计的，可算）。
- $p(\mathbf{z})$：是先验标准高斯（已知的，可算）。
总结： 变分推断通过 放弃追求精确解 （因为积分积不出来），转而追求最优近似解（在一个简单的分布家族里找最像的）。因为这个“简单的分布家族”是我们自己选的（高斯），所以它是完全可解的。

现在我们知道了VAE的encoder和decoder是怎么来的，那么这两个东西具体是怎么工作的呢？
## 模型拆解
首先需要明确一点，VAE的论文正文的方法阐述部分并没有直接介绍encoder和decoder的具体模型，而是用p和q来表示这两个模型的分布，然后基于这两个分布提出了SGVB估计器和AEVB算法。

在Example部分，作者使用了神经网络来估计encoder $q_\phi(z|x)$ 的，然后做了四个假设：
1. 先验分布 $p_\theta(\mathbf z)$ 为一个标准高斯分布（论文提及，此时的先验分布没有参数theta） $p(\mathbf z) = \mathcal N(\mathbf z;\bf 0,\bf I)$
2. 似然分布（decoder） $p_\theta(\mathbf x|\mathbf z)$ 为一个高斯分布 $p_\theta(\mathbf x|\mathbf z) = \mathcal N(\mathbf x; \mu_\theta(\mathbf z), \sigma^2 \bf I)$（0-1数值情况下为伯努利分布），分布参数由z输入decoder模型估计得到。
3. 真实的（不可解的）后验分布 $p_\theta(\mathbf z|\mathbf x)$ 为一个对角协方差矩阵的高斯分布（Gaussian with a diagonal covariance）
4. 基于3才有了我们变分近似后验（encoder） $q_\phi(\mathbf z|\mathbf x)$ 也是一个对角协方差矩阵的高斯分布 $q_\phi(\mathbf z|\mathbf x^{(i)}) = \mathcal N(\mathbf z;\mu_\phi(\mathbf x^{(i)}),\sigma_\phi^2(\mathbf x^{(i)})\bf I)$ ，它的均值和方差由一个神经网络根据输入x来估计（注意原论文中这个写法其实不太对，因为把方差写成 $\sigma^2I$ 表示对角线都是同一个元素，表示各向同性高斯分布；而实际上我们用神经网络生成的方差是一个向量，协方差矩阵的对角线是可以有不同值的，所以方差应该写成 $\mathcal N(\mathbf z;\mu^{(i)},diag (\sigma^{2(i)}))$）
> 注意，神经网络**不能**直接表示一个概率分布，因为神经网络只能表示一个输入到输出的确定性映射，无法表示一个随机变量的分布。这里的编码器部分的神经网络输出是一个高斯分布的均值和方差（实际是由两个线性层分别输出），再在这个高斯分布中采样得到z，这样的z才是一个随机变量。所以不能简单地说神经网络就是encoder $q_\phi(z|x)$ 。
同样的道理，decoder $p_\theta(x|z)$ 也不能直接用神经网络表示，神经网络输出的也是一个高斯分布的均值和方差，理论上也需要用这两个参数构建一个高斯分布，再在这个分布里采样才能得到输出的x'。但是实现上基本都简化了，我们只用神经网络输出均值，省略了方差，用均值直接当做采样输出了。

> 引自苏剑林博客：
> ![苏剑林的vae结构](/resource/vae_struct_by_sujianlin.png)

所以我们可以比较清晰的看到在VAE中，两个模型encoder和decoder的作用都是用来得到高斯分布的参数：encoder输入的是真实数据，输出的是后验分布的均值和方差；decoder输入的是隐态z，输出的是似然分布的均值（和方差）。其中我们获取隐态数据z以及重构数据x'的动作都是**采样**实现的。
总结一下整体的前向流程：
1. 输入真实数据 $\mathbf x^{(i)}$ ，通过encoder得到近似后验分布的均值和方差 $\mu^{(i)},\sigma^{2(i)}$
2. 从近似后验分布中采样得到隐态数据 $\mathbf{z}^{(i)} \sim \mathcal N(\mathbf z;\mu^{(i)},\sigma^{2(i)}\bf I)$
3. 将z输入decoder得到似然分布的均值 $\mu_\theta(\mathbf z)$
4. 从似然分布中采样得到重构数据 $\tilde {\mathbf{x}}^{(i)} \sim \mathcal N(\mathbf x;\mu_\theta(\mathbf z), \sigma^2 \bf I)$

注意在实际编码中，第4步常常被省略，直接用似然分布的均值作为重构数据。

## 证据下界(evidence lower bound, ELBO)
$\log p_\theta(x)$ 的证据下界(ELBO)

$$
\mathbf{L}=-D_{KL}(q_{\phi}(\mathbf z|\mathbf x^{(i)})||p_{\theta}(\mathbf z))+\Bbb E_{q_{\phi}(\mathbf z|\mathbf x^{(i)})}[\log p_{\theta}(\mathbf x^{(i)}|\mathbf z)]
$$

这个式子是用KL散度的定义推出来的

$$
D_{KL}(q(\mathbf z|\mathbf x)||p(\mathbf z|\mathbf x))=\Bbb E_{z\sim q}[\log q(\mathbf z|\mathbf x)-\log p(\mathbf z|\mathbf x)]
\newline=\Bbb E_{z\sim q}\Big[\log q(\mathbf z|\mathbf x) - \log \frac {p(\mathbf x|\mathbf z)p(\mathbf z)} {p(\mathbf x)}\Big]
\newline=\Bbb E_{z\sim q}\Big[\log q(\mathbf z|\mathbf x) - \log p(\mathbf x|\mathbf z) -\log p(\mathbf z) + \log p(\mathbf x)\Big ]
\newline=\log p(\mathbf x) +\Bbb E_{z\sim q}\Big[\log q(\mathbf z|\mathbf x) - \log p(\mathbf x|\mathbf z) -\log p(\mathbf z) \Big ]
$$

观察到 $\log p(\mathbf x)$ 就是我们希望最大化的目标函数，因此改写此式为：

$$
\log p(\mathbf x)=D_{KL}(q(\mathbf z|\mathbf x)||p(\mathbf z|\mathbf x))+\Bbb E_{z\sim q}\Big[-\log q(\mathbf z|\mathbf x) + \log p(\mathbf x|\mathbf z) +\log p(\mathbf z) \Big ]\\
=D_{KL}(q(\mathbf z|\mathbf x)||p(\mathbf z|\mathbf x))- D_{KL}(q(\mathbf z|\mathbf x)||p(\mathbf z)) + \Bbb E_{z\sim q}[\log p(\mathbf x|\mathbf z)]
$$

因为等是右边的第一项是KL散度，一定大于0,因此有

$$
\log p(\mathbf x)\ge - D_{KL}(q(\mathbf z|\mathbf x)||p(\mathbf z)) + \Bbb E_{z\sim q}[\log p(\mathbf x|\mathbf z)]
$$

不等号右边即为证据下界
> 证据下界中的“证据”(evidence)指的是数据的边际概率，即 $p_\theta(\mathbf x)$。VAE的目标是最大化 $\log p_\theta(x)$ ，根据上边的推导，它的下界就是证据下界。

## 损失函数
上边得到的ELBO是根据散度定义和贝叶斯定理推导而来的，是一个VB的核心结论，VAE只是借用。我们的目的是最大化 $\log p_\theta(\mathbf x)$，等价于求它上限的最大化，即求

$$
\theta^{best}=\displaystyle \arg\max_\theta ELBO
$$

我们习惯于将损失函数定义为一个求最小的函数，因此

$$
\theta^{best}=\displaystyle \arg\min_\theta -ELBO
$$

所以损失函数为

$$
L=D_{KL}(q_\phi(\mathbf z|\mathbf x)||p_\theta(\mathbf z)) + \Bbb E_{z\sim q_\phi}[-\log p_\theta(\mathbf x|\mathbf z)]
$$

第一项称为正则项，第二项称为重构误差。正则项比较简单，因为两个分布 $q_\phi(\mathbf z|\mathbf x),p_\theta(\mathbf z)$ 都是高斯分布且参数都已知（先验是标准高斯，后验的均值和方差是encoder的输出），因此KL散度可以直接计算。
> 为什么KL散度是正则项？每个输入的数据都会产生一个独立的正态分布（均值和方差），重参数化后即加入了基于这个方差的噪声进行训练。训练过程会逐渐让噪声归零，也就是会让方差趋近于0，这其实就回到了AE。为了避免这这种情况，我们需要加一个正则，让方差趋近于1，即让 $q_\phi$ 去逼近标准正态分布[3]。

这里重点说一下重构误差项。原论文用SGVB估计器来估计这个重构误差项，还专门设计了一套AEVB的算法，其实就是重参数化+蒙特卡洛估计。但是很多代码实现中，重构误差项直接用MSE来估计，很多人这里都没讲清楚。网友的视频[6]中有提到，这个估计实际等于一个MSE，但并未给出原理推导。这里其实主要做了两步近似：

1.  **蒙特卡洛估计 (Monte Carlo Estimation)**
    将重构误差项的期望 $\Bbb E_{z \sim q_\phi(z|x)}[\cdots]$ 通过采样近似。在 VAE 训练中，通常为了效率，单次采样的样本数 $L$ 设为 1：

    $$\Bbb{E}_{z \sim q_\phi(z|x)}[-\log p_\theta(x|z)] \approx -\frac{1}{L}\sum_{l=1}^L \log p_\theta(x|z^{(l)}) \approx -\log p_\theta(x|z)$$

    其中 $z$ 是通过重参数化技巧 $z = \mu + \sigma \odot \epsilon$ 采样得到的。

2.  **分布假设 (Distribution Assumption)**
    我们需要显式定义解码器 $p_\theta(x|z)$ 的分布形式，这直接决定了重构损失的具体公式。

    *   **情况一：高斯分布假设 $\rightarrow$ MSE Loss**
        假设数据 $x$ 是连续值（如实数值的图像像素），通常假设 $p_\theta(x|z)$ 服从各向同性的高斯分布：

        $$p_\theta(x|z) = \mathcal{N}(x; \mu_\theta(z), \sigma^2 \bf I)$$

        其中 $\mu_\theta(z)$ 是解码器神经网络的输出， $\sigma$ 是标准差。
        写出其对数似然函数（Log-Likelihood）：

        $$\log p_\theta(x|z) = \log \left( \frac{1}{(2\pi\sigma^2)^{D/2}} \exp\left( -\frac{\|x - \mu_\theta(z)\|^2}{2\sigma^2} \right) \right)$$

        展开对数项：

        $$=\underbrace{-\frac{D}{2}\log(2\pi) - D\log\sigma}_{\text{常数项 (Constant)}} - \frac{1}{2\sigma^2}\underbrace{\|x - \mu_\theta(z)\|^2}_{\text{平方误差 (SSE)}}$$

        **关于 $\sigma$ 的假设**：
        理论上，$\sigma$ 确实可以是 Decoder 神经网络输出的一部分（即模型不仅预测均值 $\mu$，也预测方差 $\sigma$）。
        但在 VAE 的**大多数实际实现**中，为了简化模型和训练稳定性，我们通常做一个**简化假设**：假设 $\sigma$ 是一个所有数据点都共享的、固定的超参数（不随 $z$ 变化）。
        
        如果我们设定这个固定值为 $\sigma=1/\sqrt{2}$（这是一个很常见的工程设定），那么 $\frac{1}{2\sigma^2} = 1$，常数项也可以忽略。此时，最小化负对数似然就完全等价于最小化均方误差（MSE）：

        $$\mathbf{L}_{recon} = -\log p_\theta(x|z)\propto\|x - \mu_\theta(z)\|^2 = \|x - x_{recon}\|^2$$

        这就是为什么很多代码直接使用 MSE 作为重构 Loss 的原因。
        *注意：如果你真的让网络去学习 $\sigma$，那么 MSE 前面会带有一个权重项，且 Loss 中会包含 $\log \sigma$ 项以防止 $\sigma$ 塌缩到 0。*

    *   **情况二：伯努利分布假设 $\rightarrow$ BCE Loss**
        如果数据是二值的（或者归一化到 [0, 1] 区间并视为概率），通常假设 $p_\theta(x|z)$ 服从多变量伯努利分布。此时推导出的重构 Loss 就是二元交叉熵损失（Binary Cross Entropy, BCE）。

        $$\log p_\theta(x|z) = \sum_{i=1}^D [x_i \log y_i + (1-x_i) \log (1-y_i)]$$

        其中 $y = \mu_\theta(z)$ 是解码器输出（经过 Sigmoid 激活）。


> 有视频说，VAE的损失函数其实就是这两个项之间的博弈：一方面，重构项缩小就要求噪声尽量低，就会让encoder输出的方差减少到0；而另一方面正则项要缩小就要求encoder输出的方差要趋近于1。这两个项相互博弈才让VAE找到一种平衡，能输出图片。
## 重参数化
先看论文原文对重参数化的描述：
> Let z be a continuous random variable, and $\mathbf z \sim q_\phi(\mathbf z|\mathbf x)$ be some conditional distribution. It is then often possible to express the random variable z as a deterministic variable $\mathbf z = g_\phi(\epsilon, \mathbf x)$ , where $\epsilon$ is an auxiliary variable with independent marginal $p(\epsilon)$ , and $g_\phi(.)$ is some vector-valued function parameterized by φ.

理解一下，我们取z的过程是从某个分布中随机采样，这个过程呢在训练中无法求梯度，因为随机采样过程不可导。而重参数化就是为了解决这个问题，我们把这个随机采样的过程等价于一个确定性的函数 $g_\phi(\epsilon, \mathbf x)$ ，其中 $\epsilon$ 可以看成一个随机噪声，服从某个确定性分布 $p(\epsilon)$ 。

## VAE 与变分贝叶斯推断 (Variational Bayes Inference, VI) 的关系

在统计推断中，核心任务往往是计算潜变量的后验分布 $p_\theta(\mathbf{z}|\mathbf{x})$ 一般称为推断任务。针对这一不可解问题，主要存在两大类推断框架：
1.  **蒙特卡洛推断 (Monte Carlo Inference)**: 通过构建马尔可夫链来从目标分布中采样（如 MCMC, Gibbs Sampling）。这类方法理论上是无偏的，且随时间收敛到精确解，但计算开销巨大，难以扩展到大规模数据集。
2.  **变分推断 (Variational Inference, VI)**: 将推断问题转化为优化问题。寻找一个变分分布族 $\mathcal{Q}$ 中的最优分布 $q^*(\mathbf{z})$ 来近似真实后验。

VAE 正是建立在**变分推断**的理论基础之上，但它对传统方法做出了突破性的改进。

### 1. 传统变分推断

在 VAE 出现之前，变分推断主要依赖 **平均场假设 (Mean-Field Assumption)** 和 **坐标上升法 (Coordinate Ascent)** 来求解。

**核心思想**：
既然真实的后验 $p(\mathbf{z}|\mathbf{x})$ 难以计算，我们就在一个受限的分布族 $\mathcal{Q}$ 中寻找一个最优分布 $q^*(\mathbf{z})$ 来近似它。为了使问题可解，我们通常假设 $q(\mathbf{z})$ 满足**平均场假设**，即潜变量的各个维度是相互独立的：
$$
q(\mathbf{z}) = \prod_{j=1}^M q_j(z_j)
$$
这一假设将一个复杂的高维优化问题分解成了 $M$ 个一维优化问题。

**求解方法：坐标上升变分推断 (CAVI)**
基于平均场假设，我们可以通过 **Coordinate Ascent Variational Inference (CAVI)** 算法迭代求解。
CAVI 的核心目标依然是**最大化 ELBO**。在平均场假设下，ELBO 可以展开为关于每个 $q_j$ 的泛函。
通过对 ELBO 求关于 $q_j$ 的偏导并令其为 0，我们可以推导出最优的 $q_j^*(z_j)$ 更新公式：

$$
\ln q_j^*(z_j) = \mathbb{E}_{i \neq j} [\ln p(\mathbf{x}, \mathbf{z})] + \text{const}
$$

这意味着，只要模型采用了**共轭先验 (Conjugate Priors)**（如指数族分布），我们就可以推导出 $q_j^*(z_j)$ 的**闭式解 (Closed-form solution)**。
**注意**：传统 VI 同样是在优化 ELBO，只是优化手段是“坐标上升”而非 VAE 的“梯度下降”。
> **共轭先验 (Conjugate Prior)** 指的是这样一种先验分布：
当它与似然函数（Likelihood）相乘计算后验分布时，得到的**后验分布与先验分布属于同一个分布家族**。
**公式表达**：
$\text{Posterior} \propto \text{Likelihood} \times \text{Prior}$ 如果 $\text{Prior} \in \mathcal{F}$ 且 $\text{Posterior} \in \mathcal{F}$（其中 $\mathcal{F}$ 是某个分布族，如高斯分布族、Beta 分布族），那么我们就说这个先验是该似然的**共轭先验**。
**举例**：
    1.  **Beta-Binomial 共轭**：
    *   似然：二项分布 (Binomial) —— 比如抛硬币。
    *   先验：Beta 分布。
    *   结果：后验依然是 Beta 分布。
    *   *好处*：计算极其简单，只需要把观测到的正面次数加到 Beta 分布的参数 $\alpha$ 上，反面次数加到 $\beta$ 上即可。
    2.  **Gaussian-Gaussian 共轭**：
    *   似然：高斯分布（已知方差，估计均值）。
    *   先验：高斯分布。
    *   结果：后验依然是高斯分布。
**为什么重要？**
在传统贝叶斯推断中，共轭先验能让我们**直接写出后验分布的解析解 (Closed-form solution)**，从而避免了复杂的积分运算。
但在 VAE 这种深度学习模型中，似然函数由复杂的神经网络构成，不再具有共轭性质，所以才需要变分推断和重参数化技巧。

**传统 VI 的局限性**：
1.  **推导复杂**：需要针对特定模型手动推导每个 $q_j$ 的更新公式，一旦模型结构改变（如增加一层网络），所有公式都需要重新推导。
2.  **依赖共轭**：强烈依赖共轭先验假设，限制了模型的表达能力，难以应用到非线性极强的深度神经网络中。
3.  **计算昂贵**：CAVI 需要在整个数据集上进行迭代，或者针对每个新数据点重新运行迭代优化过程，无法像神经网络那样进行高效的 Batch 训练和单次前向推理。

### 2. VAE 的创新
#### Amortized Inference
VAE 引入了 **摊销推断 (Amortized Inference)** 的思想，这是其与传统 VI 的根本区别。
VAE 不再为数据集中的每一个样本 $\mathbf{x}^{(i)}$ 单独求解一组变分参数 $\phi^{(i)}$ ，而是训练一个**全局的推断网络 (Inference Network)**（即 Encoder）来预测这些参数：

$$
\phi^{(i)} = f_\phi(\mathbf{x}^{(i)})
$$

$$
q_\phi(\mathbf{z}|\mathbf{x}^{(i)}) \approx p_\theta(\mathbf{z}|\mathbf{x}^{(i)})
$$

这里的 $\phi$ 是神经网络的权重，是被所有数据点共享的。
*   **优势**：将推断的时间复杂度从迭代求解降低为一次前向传播 (Forward Pass)。
*   **代价**：引入了**摊销差距 (Amortization Gap)**，即即便是最优的 Encoder 也可能无法完美拟合每个数据点的最优变分参数。

#### SGVB Estimator
为了在神经网络框架下进行端到端的梯度优化，VAE 摒弃了传统 VI 对共轭先验 (Conjugate Priors) 的依赖，提出了 **SGVB (Stochastic Gradient Variational Bayes)** 估计器。
通过 **重参数化技巧 (Reparameterization Trick)**，将随机性从采样过程中剥离，使得梯度能够通过随机节点反向传播：

$$
\mathbf{z} = \mu_\phi(\mathbf{x}) + \sigma_\phi(\mathbf{x}) \odot \boldsymbol{\epsilon}, \quad \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})
$$

这使得我们可以直接对 ELBO 进行随机梯度下降 (SGD) 优化。
#### 总结
VAE 本质上是将 **深度学习 (Deep Learning)** 的强拟合能力与 **变分推断 (Variational Inference)** 的严谨数学框架相结合的产物。
*   它保留了 VI 的核心目标：最大化 ELBO。
*   它改进了 VI 的求解方式：用 Amortized Inference 替代 Mean-Field Update，用 SGVB 替代 Closed-form Update。
## 参考资料
> [1] [VAE论文](https://arxiv.org/pdf/1312.6114)  
> [2] [关于AE、VAE的一篇综述论文](https://arxiv.org/pdf/2003.05991)  
> [3] [苏剑林博客](https://kexue.fm/archives/5253)  
> [4] [翁丽莲博客](https://lilianweng.github.io/posts/2018-08-12-vae/)   
> [5] [什么是推断、变分推断、变分贝叶斯推断](https://zhuanlan.zhihu.com/p/575328650)  
> [6] [VAE介绍视频](https://www.bilibili.com/video/BV1Mgh4zJEZV)   
